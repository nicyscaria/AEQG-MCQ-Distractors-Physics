{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This ipynb notebook can be used to create questions for different topics  at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    " \n",
    "load_dotenv()\n",
    "\n",
    "TOGETHER_KEY = os.getenv('TOGETHER_API_KEY')\n",
    "OPENAI_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_together import ChatTogether\n",
    " \n",
    "from typing import List\n",
    " \n",
    "topic_identifier_system = \"\"\"Analyze user input and identify the physics topic mentioned in the input. Do not return the input text.\n",
    "For example:\n",
    "- \"Create questions about velocity\" -> \"velocity\"\n",
    "- \"Explain displacement\" -> \"displacement\"\n",
    " \n",
    "Return only the identified physics topic name as given in the input.\"\"\"\n",
    " \n",
    "topic_check = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", topic_identifier_system),\n",
    "   (\"placeholder\", \"{messages}\")\n",
    "]) | ChatTogether(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\", temperature=0\n",
    "    )\n",
    " \n",
    "input = \"Create 5 questions on energy.\"\n",
    " \n",
    "topic = topic_check.invoke({\"messages\": [(\"user\", input)]}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_together import ChatTogether\n",
    "\n",
    "import json\n",
    "\n",
    "system_prompt = (\n",
    "    \"Create one multiple choice question for {skill} level of Bloom's taxonomy for a 12th grade Physics student in India on {topic}.\"\n",
    "    \"Requirements:\"\n",
    "    \"Student should only be able to answer if they've mastered the concept\"\n",
    "    \"Each distractor must address either: A specific misconception about {topic} or A prerequisite knowledge gap\"\n",
    "    \"Language and complexity suitable for 12th grade\"\n",
    "    \"Physics context and application\"\n",
    "    \"Format as the output as a JSON:\"\n",
    " \n",
    "        \"\"\"{{{{\n",
    "        \"question\": \"\",\n",
    "        \"skill\": \"\"\n",
    "        \"options\": {{\"a\": \"\", \"b\": \"\", \"c\": \"\", \"d\": \"\"}},\n",
    "        \"correct\": \"\",\n",
    "        \"explanation\": {{\n",
    "            \"correct\": \"\",\n",
    "            \"a\": \"misconception/prerequisite tested\",\n",
    "            \"b\": \"\", \"c\": \"\", \"d\": \"\"\n",
    "        }}\n",
    "        }}}}\"\"\"\n",
    " \n",
    "    \"For {skill} level, ensure:\"\n",
    "    \"{skill_requirement}\"\n",
    "    \"Make sure there are no additional information being other than the output in the format that is asked for.\"\n",
    "    \"Since you are not capable of creating images, ensure the question does not reference any image. The question should be fully self-contained\"\n",
    ")\n",
    "\n",
    "skill_requirements = {\n",
    "   \"Remember\": \"Question tests ability to retrieve relevant knowledge from long-term memory.\",\n",
    "   \"Understand\": \"Question tests ability to onstruct meaning from instructional messages, including oral, written, and graphic communication.\",\n",
    "   \"Apply\": \"Question tests ability to carry out or use a procedure in a given situation.\",\n",
    "   \"Analyze\": \"Question tests ability to break material into foundational parts and determine how parts relate to one another and the overall structure or purpose.\",\n",
    "   \"Evaluate\": \"Question tests ability to make judgments based on criteria and standards.\"\n",
    "}\n",
    " \n",
    "skills = [\"Remember\", \"Understand\", \"Apply\", \"Analyze\", \"Evaluate\"]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatTogether(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "    )\n",
    "\n",
    "query = {\"input\": '{input}'}\n",
    "\n",
    "topics = [ ] # Add topics here\n",
    "\n",
    "\n",
    "def generate_assessment(llm):\n",
    "    all_responses = []\n",
    "    model_name = llm.model_name.split('/')[-1]\n",
    "    \n",
    "    # Process all topics\n",
    "    for topic in topics:\n",
    "        responses = {\n",
    "            \"topic\": topic,\n",
    "            \"questions\": []\n",
    "        }\n",
    "        \n",
    "        for skill in skills:\n",
    "            prompt = system_prompt.format(\n",
    "                skill=skill,\n",
    "                topic=topic,\n",
    "                skill_requirement=skill_requirements[skill]\n",
    "            )\n",
    "            response = llm.invoke(prompt)\n",
    "            cleaned_content = response.content.strip()\n",
    "            if cleaned_content.startswith(\"```json\"):\n",
    "                cleaned_content = cleaned_content[7:-3]\n",
    "                \n",
    "            try:\n",
    "                question_json = json.loads(cleaned_content)\n",
    "                responses[\"questions\"].append(question_json)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing {topic} - {skill} response\")\n",
    "                print(response)\n",
    "        \n",
    "        # Save individual JSON if needed\n",
    "        json_filename = f\"LLM_{topic}_{model_name}.json\"\n",
    "        with open(json_filename, \"w\") as f:\n",
    "            json.dump(responses, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        all_responses.extend(\n",
    "            {\"topic\": topic, **question} \n",
    "            for question in responses[\"questions\"]\n",
    "        )\n",
    "    \n",
    "    # Convert all responses to CSV\n",
    "    csv_data = []\n",
    "    max_options = 0\n",
    "    \n",
    "    # First pass to find maximum number of options across all questions\n",
    "    for response in all_responses:\n",
    "        max_options = max(max_options, len(response.get(\"options\", [])))\n",
    "    \n",
    "    # Second pass to create rows\n",
    "    for response in all_responses:\n",
    "        options = response.get(\"options\", {})\n",
    "        explanations = response.get(\"explanation\", {})\n",
    "        \n",
    "        row = {\n",
    "            \"topic\": response[\"topic\"],\n",
    "            \"skill\": response.get(\"skill\", \"\"),\n",
    "            \"question\": response.get(\"question\", \"\"),\n",
    "            \"correct_option\": response.get(\"correct\", \"\"),\n",
    "            \"correct_explanation\": explanations.get(\"correct\", \"\")\n",
    "        }\n",
    "        \n",
    "        # Add option and explanation columns vrgg for each letter\n",
    "        for letter in ['a', 'b', 'c', 'd']:\n",
    "            row[f\"option_{letter}\"] = options.get(letter, \"\")\n",
    "            row[f\"explanation_{letter}\"] = explanations.get(letter, \"\")\n",
    "        \n",
    "        csv_data.append(row)\n",
    "    \n",
    "    # Save consolidated CSV\n",
    "    csv_filename = f\"LLM_all_topics_{model_name}.csv\"\n",
    "    if csv_data:\n",
    "        df = pd.DataFrame(csv_data)\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        \n",
    "\n",
    "generate_assessment(llm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auro_mcq_distractors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
